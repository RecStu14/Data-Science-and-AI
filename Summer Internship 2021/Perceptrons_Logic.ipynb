{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptrons_Logic",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG4eeDbwaT-t",
        "outputId": "e4da1eb2-d2b3-42b5-ae6f-1335a75016d5"
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvI25_U8aiEj"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQa_zn_CtVM1"
      },
      "source": [
        "# Input Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFkadS5_hQY8"
      },
      "source": [
        "Syntax used: torch.tensor\n",
        "\n",
        "torch.tensor is a multi-dimensional matrix containing elements of a single datatype."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPCy2ZcLaqP4",
        "outputId": "8b3dc7aa-a4aa-403a-90bd-10ebc864cc2f"
      },
      "source": [
        "# Perceptron - algorithm that classifies into binary outcomes, either 0 or 1. \n",
        "#AND \n",
        "# Creating input tensor\n",
        "input_tensor = torch.tensor([(0,0,1), (0,1,1), (1,0,1), (1,1,1)], dtype = torch.double)\n",
        "print(input_tensor)\n",
        "\n",
        "#The 3rd column would be the bias."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 1.],\n",
            "        [0., 1., 1.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJlghLbuqGTF"
      },
      "source": [
        "# AND"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8twYQkyxgW_w",
        "outputId": "a64f917a-959c-4cd0-d85d-47a24e8fbd7a"
      },
      "source": [
        "# Creating the matric with the weights \n",
        "\n",
        "and_weights = torch.tensor([(10, 10, -20)], dtype = torch.double)\n",
        "print(and_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 10.,  10., -20.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHrxdH4gkFsT",
        "outputId": "3fca33f5-1583-474a-82b2-ec1204571f41"
      },
      "source": [
        "# Check the size of the matrices\n",
        "print(\"input_tensor = \", input_tensor.shape)\n",
        "print(\"and_weights = \", and_weights.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_tensor =  torch.Size([4, 3])\n",
            "and_weights =  torch.Size([1, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6o72XLTkmk0",
        "outputId": "59812041-57d1-481f-affb-63f7b0a3168b"
      },
      "source": [
        "# Carry out Matrix Multiplication => and_weights * input_tensor\n",
        "and_logic = and_weights.mm(input_tensor.t()) \n",
        "print(and_logic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-20., -10., -10.,   0.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoafSQ8FsiV6",
        "outputId": "26e5c242-352e-46f6-b062-8ea4a094229a"
      },
      "source": [
        "# ___t.() transposes the matrix, from 4x3 to 3x4, therefore matrix multiplication is 1x3 * 3x4 = 1x4\n",
        "input_tensor.t()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., 1.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [1., 1., 1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe7d7BjRk1xf",
        "outputId": "279663fa-92db-4128-c87b-9fc7b7f2ab82"
      },
      "source": [
        "# Replacing the values with 0 and 1\n",
        "and_output = [[1 if i>= 0 else 0 for i in x ]for x in and_logic]\n",
        "print(and_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 0, 0, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhe-cLASqNdF"
      },
      "source": [
        "# OR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDi59PjHnAlQ",
        "outputId": "a48ac337-2af6-4438-88b1-c312a46ddbf5"
      },
      "source": [
        "# Using the same input_tensor\n",
        "# Creating the OR_weights\n",
        "\n",
        "or_weights = torch.tensor([(20, 20, -10)], dtype = torch.double) #NOTE: the 3rd element is the BIAS\n",
        "print(or_weights)\n",
        "print(\"or_weights = \", or_weights.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 20.,  20., -10.]], dtype=torch.float64)\n",
            "or_weights =  torch.Size([1, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi8uf5WXpIp4",
        "outputId": "7237c4ef-6ed0-4ccf-f576-04aec6b73dec"
      },
      "source": [
        "# Matrix Multiplication\n",
        "or_logic = or_weights.mm(input_tensor.t())\n",
        "print(or_logic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-10.,  10.,  10.,  30.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPfSne_bphux",
        "outputId": "8e471f70-f901-474e-f0ae-0c9dba0c339b"
      },
      "source": [
        "or_output = [[1 if i>= 0 else 0 for i in x] for x in or_logic]\n",
        "print(or_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 1, 1, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6859HZXOqSwV"
      },
      "source": [
        "# NOT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8-fMLV3pvmJ",
        "outputId": "0a268558-9389-4537-fe68-668c2d28d380"
      },
      "source": [
        "not_weights = torch.tensor([(10, -20, 1)], dtype = torch.double)\n",
        "not_logic = not_weights.mm(input_tensor.t())\n",
        "not_output = [[1 if i>= 0 else 0 for i in x]for x in not_logic]\n",
        "print(not_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 0, 1, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZmxZstNrUA5"
      },
      "source": [
        "# XOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY9v1iPyqzW7"
      },
      "source": [
        "# XOR\n",
        "# 0 0 | 0\n",
        "# 0 1 | 1\n",
        "# 1 0 | 1\n",
        "# 1 1 | 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBGcim6LVqkd"
      },
      "source": [
        "We are unable to implement the XOR Logic using just a Perceptron as the classes of the XOR Logic cannot be linearly separable, which means we cannot separate (0,0), (1,0), (0,1), (1,1) using just a linear line. Hence, we would need a neural network with mulitple layers."
      ]
    }
  ]
}